{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14595189,"sourceType":"datasetVersion","datasetId":9322895},{"sourceId":10414190,"sourceType":"datasetVersion","datasetId":6454328}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ¦´ Vertebrae Segmentation Pipeline - Kaggle Training\n\nThis notebook trains the complete 3-stage pipeline using **CLI commands**.\n\n## Steps:\n1. Clone repository from GitHub\n2. Install dependencies\n3. Run training commands for each stage\n4. Export trained models","metadata":{}},{"cell_type":"code","source":"# Install required packages\n!pip install SimpleITK nibabel tensorboard scipy pandas scikit-learn tqdm --quiet\n\nimport sys\nimport os\nimport torch\n\nprint(f\"Python: {sys.version}\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CONFIGURE YOUR GITHUB REPOSITORY\n# ============================================================\nGITHUB_REPO = \"https://github.com/YOUR_USERNAME/YOUR_REPO.git\"  # <-- CHANGE THIS\n\nREPO_NAME = GITHUB_REPO.split('/')[-1].replace('.git', '')\n\n%cd /kaggle/working\n\n# Clone if not exists\nif not os.path.exists(REPO_NAME):\n    !git clone {GITHUB_REPO}\n    print(f\"âœ… Cloned {REPO_NAME}\")\nelse:\n    print(f\"âœ… Repository exists, pulling latest...\")\n    %cd {REPO_NAME}\n    !git pull\n    %cd ..\n\n# Add to Python path\nPIPELINE_DIR = f\"/kaggle/working/{REPO_NAME}\"\nsys.path.insert(0, PIPELINE_DIR)\n\n# Verify\n!ls {REPO_NAME}/pytorch_pipeline/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CONFIGURE PATHS\n# ============================================================\nDATASET_CSV = \"/kaggle/input/verse19/dataset.csv\"  # <-- CHANGE THIS\nOUTPUT_DIR = \"/kaggle/working/outputs\"\nFOLD = 0\nNUM_FOLDS = 5\nDEVICE = \"cuda\"\n\n# Training epochs\nEPOCHS_STAGE1 = 100\nEPOCHS_STAGE2 = 150\nEPOCHS_STAGE3 = 100\nBATCH_SIZE = 2\nLR = 0.0001\n\n# ============================================================\n# QUICK TEST MODE\n# ============================================================\nQUICK_TEST = True  # <-- Set to False for full training\n\nif QUICK_TEST:\n    EPOCHS_STAGE1 = 3\n    EPOCHS_STAGE2 = 3\n    EPOCHS_STAGE3 = 3\n    print(\"âš ï¸ QUICK TEST MODE: 3 epochs per stage\")\n\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"Dataset: {DATASET_CSV}\")\nprint(f\"Output: {OUTPUT_DIR}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# ðŸš€ Stage 1: Spine Localization","metadata":{}},{"cell_type":"code","source":"%cd {PIPELINE_DIR}\n\nprint(\"=\"*70)\nprint(\"STAGE 1: SPINE LOCALIZATION\")\nprint(\"=\"*70)\n\n!python -m pytorch_pipeline.train \\\n    --stage spine \\\n    --csv {DATASET_CSV} \\\n    --output {OUTPUT_DIR} \\\n    --fold {FOLD} \\\n    --num_folds {NUM_FOLDS} \\\n    --epochs {EPOCHS_STAGE1} \\\n    --batch_size {BATCH_SIZE} \\\n    --lr {LR} \\\n    --device {DEVICE}\n\nprint(\"\\nâœ… Stage 1 Complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# ðŸš€ Stage 2: Vertebrae Localization","metadata":{}},{"cell_type":"code","source":"print(\"=\"*70)\nprint(\"STAGE 2: VERTEBRAE LOCALIZATION\")\nprint(\"=\"*70)\n\n!python -m pytorch_pipeline.train \\\n    --stage vertebrae \\\n    --csv {DATASET_CSV} \\\n    --output {OUTPUT_DIR} \\\n    --fold {FOLD} \\\n    --num_folds {NUM_FOLDS} \\\n    --epochs {EPOCHS_STAGE2} \\\n    --batch_size {BATCH_SIZE} \\\n    --lr {LR} \\\n    --device {DEVICE}\n\nprint(\"\\nâœ… Stage 2 Complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# ðŸš€ Stage 3: Vertebrae Segmentation","metadata":{}},{"cell_type":"code","source":"print(\"=\"*70)\nprint(\"STAGE 3: VERTEBRAE SEGMENTATION\")\nprint(\"=\"*70)\n\n!python -m pytorch_pipeline.train \\\n    --stage segmentation \\\n    --csv {DATASET_CSV} \\\n    --output {OUTPUT_DIR} \\\n    --fold {FOLD} \\\n    --num_folds {NUM_FOLDS} \\\n    --epochs {EPOCHS_STAGE3} \\\n    --batch_size {BATCH_SIZE} \\\n    --lr {LR} \\\n    --device {DEVICE}\n\nprint(\"\\nâœ… Stage 3 Complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# ðŸ§ª Test Inference","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(DATASET_CSV)\nTEST_IMAGE = df.iloc[0]['image_path']\n\nprint(f\"Testing inference on: {TEST_IMAGE}\")\n\n!python -m pytorch_pipeline.infer \\\n    --image {TEST_IMAGE} \\\n    --model_dir {OUTPUT_DIR} \\\n    --output {OUTPUT_DIR}/inference_test \\\n    --device {DEVICE} \\\n    --save_intermediates\n\nprint(\"\\nâœ… Inference Complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nzip_path = f\"/kaggle/working/trained_models_fold{FOLD}\"\nshutil.make_archive(zip_path, 'zip', OUTPUT_DIR)\n\nprint(f\"âœ… Created: {zip_path}.zip\")\nprint(f\"ðŸ“¥ Download from Output tab!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}